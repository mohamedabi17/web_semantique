# üéì Projet Master 2 - Web S√©mantique
## Extraction de Graphes de Connaissances avec LLM & Architecture T-Box/A-Box

**√âtudiant:** Master 2 Web S√©mantique  
**Date:** 16 janvier 2026  
**Sujet:** Sujet 1 - Architecture T-Box/A-Box avec R√©ification  
**Technologies:** Python 3.12, RDFLib, spaCy, Groq API (Llama-3.1), OWL 2, RDFS

---

## üöÄ Nouveaut√©s : LLM R√©el Int√©gr√© !

‚ú® **API Groq avec Llama-3.1-8B-Instant** maintenant int√©gr√©e pour l'extraction de relations s√©mantiques en temps r√©el !

```python
üöÄ Appel API Groq (Llama-3) pour : Zoubida Kedad ‚Üî Universit√© de Versailles
ü§ñ Groq/Llama-3 a d√©tect√© : Zoubida Kedad --[worksAt]--> Universit√© de Versailles
```

---

## ‚≠ê Les 3 Corrections Acad√©miques Valid√©es

### ‚úÖ 1. Restriction OWL avec BNode (Diff√©renciation OWL vs RDFS)
- Classe `ex:ValidatedCourse` avec **restriction OWL explicite**
- Contrainte ontologique : DOIT avoir au moins un `ex:author` de type `foaf:Person`
- Utilise `owl:Restriction`, `owl:onProperty`, `owl:someValuesFrom`
- Impl√©mentation avec **BNode** (n≈ìud anonyme) conforme OWL 2
- **Code** : `kg_extraction_semantic_web.py` lignes 105-136

### ‚úÖ 2. Extraction de Relations via LLM (Groq API)
- **API Groq r√©elle** avec mod√®le **Llama-3.1-8B-Instant** üî•
- Appels API authentiques (non-simulation)
- Temperature=0 pour des r√©sultats d√©terministes
- Prompt engineering optimis√© pour l'extraction de relations
- Fallback intelligent (analyse linguistique) si API indisponible
- **Code** : `kg_extraction_semantic_web.py` lignes 255-333

### ‚úÖ 3. Double S√©rialisation (Turtle + RDF/XML)
- G√©n√©ration automatique de 2 formats RDF conformes W3C
- `knowledge_graph.ttl` (Turtle - lisible par humains)
- `knowledge_graph.xml` (RDF/XML - interop√©rabilit√©)
- **Code** : `kg_extraction_semantic_web.py` lignes 826-850

**üß™ Tests automatiques :** 
```bash
python test_corrections.py  # ‚úÖ Tous les tests passent
./demo.sh                    # üé¨ D√©monstration compl√®te
```

---

## üìã Description Technique du Projet

Ce projet impl√©mente une **architecture compl√®te d'extraction de graphes de connaissances** respectant scrupuleusement les standards **OWL 2** et **RDFS** du Web S√©mantique, avec int√©gration d'un **LLM moderne** (Llama-3.1) pour l'extraction intelligente de relations.

### Architecture Impl√©ment√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         T-BOX (Sch√©ma Ontologique)      ‚îÇ
‚îÇ  ‚Ä¢ Classes OWL                          ‚îÇ
‚îÇ  ‚Ä¢ Restrictions OWL avec BNode ‚≠ê        ‚îÇ
‚îÇ  ‚Ä¢ ObjectProperties                     ‚îÇ
‚îÇ  ‚Ä¢ DatatypeProperties                   ‚îÇ
‚îÇ  ‚Ä¢ Contraintes domain/range             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           NLP Pipeline                  ‚îÇ
‚îÇ  ‚Ä¢ spaCy (NER fran√ßais)                 ‚îÇ
‚îÇ  ‚Ä¢ Groq API + Llama-3.1 ü§ñ              ‚îÇ
‚îÇ  ‚Ä¢ Analyse linguistique (fallback)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         A-BOX (Donn√©es Factuelles)      ‚îÇ
‚îÇ  ‚Ä¢ Instances de classes                 ‚îÇ
‚îÇ  ‚Ä¢ Relations s√©mantiques (LLM)          ‚îÇ
‚îÇ  ‚Ä¢ R√©ification avec m√©tadonn√©es         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Export Multi-format               ‚îÇ
‚îÇ  ‚Ä¢ Turtle (.ttl)                        ‚îÇ
‚îÇ  ‚Ä¢ RDF/XML (.xml)                       ‚îÇ
‚îÇ  ‚Ä¢ Visualisation (.png)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         A-BOX (Donn√©es)                 ‚îÇ
‚îÇ  ‚Ä¢ Extraction NER (spaCy)               ‚îÇ
‚îÇ  ‚Ä¢ Pr√©diction relations (LLM) ‚≠ê        ‚îÇ
‚îÇ  ‚Ä¢ Instanciation des entit√©s            ‚îÇ
‚îÇ  ‚Ä¢ Relations s√©mantiques                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         R√âIFICATION                     ‚îÇ
‚îÇ  ‚Ä¢ M√©tadonn√©es sur les triplets         ‚îÇ
‚îÇ  ‚Ä¢ Tra√ßabilit√© (dc:source)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    DOUBLE S√âRIALISATION ‚≠ê             ‚îÇ
‚îÇ  ‚Ä¢ Turtle (lisible)                    ‚îÇ
‚îÇ  ‚Ä¢ RDF/XML (standard W3C)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Points Cl√©s Respect√©s

### 1. D√©finition de l'Ontologie (T-Box)

‚úÖ **Classes explicites** avec `owl:Class` (ontologies standards) :
- `foaf:Person` - Repr√©sente une personne (standard FOAF)
- `schema:Place` - Repr√©sente un lieu (standard Schema.org)
- `schema:Organization` - Repr√©sente une organisation (standard Schema.org)
- `ex:Document` - Repr√©sente un document, cours ou publication
- `ex:ValidatedCourse` - **Cours valid√© avec RESTRICTION OWL** ‚≠ê

‚úÖ **ObjectProperties** (relations entre entit√©s) :
- `ex:worksAt` : foaf:Person ‚Üí schema:Organization
- `ex:teaches` : foaf:Person ‚Üí ex:Document
- `ex:studiesAt` : foaf:Person ‚Üí schema:Organization
- `ex:author` : foaf:Person ‚Üí ex:Document
- `ex:collaboratesWith` : foaf:Person ‚Üí foaf:Person
- `ex:manages` : foaf:Person ‚Üí schema:Organization
- `ex:locatedIn` : schema:Place ‚Üí schema:Place
- `ex:relatedTo` : rdfs:Resource ‚Üí rdfs:Resource (relation g√©n√©rique)

‚úÖ **DatatypeProperties** (valeurs litt√©rales) :
- `foaf:name` : foaf:Person ‚Üí xsd:string (standard FOAF)
- `ex:intitule` : ex:Document ‚Üí xsd:string
- `ex:confidence` : ex:Statement ‚Üí xsd:float (score LLM)
- `dc:source` : rdfs:Resource ‚Üí xsd:string (m√©tadonn√©es)

‚úÖ **Contraintes formelles** :
- Chaque propri√©t√© a son `rdfs:domain` et `rdfs:range` d√©finis
- Hi√©rarchie de classes respect√©e
- Conformit√© OWL 2 valid√©e

‚úÖ **Restriction OWL avec BNode (Point cl√© acad√©mique)** ‚≠ê :
```turtle
ex:ValidatedCourse rdf:type owl:Class ;
    rdfs:subClassOf ex:Document ,
        [ rdf:type owl:Restriction ;
          owl:onProperty ex:author ;
          owl:someValuesFrom foaf:Person ] .
```
- Classe `ex:ValidatedCourse` avec **restriction explicite**
- Contrainte : **DOIT avoir au moins un `ex:author` de type `foaf:Person`**
- Utilise `owl:Restriction`, `owl:onProperty`, `owl:someValuesFrom`
- Impl√©mentation avec **n≈ìud anonyme (BNode)**
- **Diff√©rencie clairement OWL 2 de RDFS simple**

### 2. Pipeline d'Extraction (A-Box)

‚úÖ **Extraction NER** avec spaCy (mod√®le fran√ßais `fr_core_news_sm`)
  - D√©tection automatique : PER (personnes), LOC (lieux), ORG (organisations)
  - Normalisation et d√©duplication des entit√©s
  
‚úÖ **Pr√©diction de relations via Groq API R√âELLE** üî• ‚≠ê :
  - Mod√®le : **Llama-3.1-8B-Instant** (Meta, 8 milliards de param√®tres)
  - Appels API authentiques (non-simulation)
  - Prompt engineering optimis√© pour extraction de relations
  - Temperature=0 pour r√©sultats d√©terministes
  - **Syst√®me de fallback √† 3 niveaux** :
    1. API Groq (inf√©rence LLM)
    2. Analyse linguistique (heuristiques spaCy)
    3. Relation par d√©faut (`ex:relatedTo`)

### 3. Technologies Utilis√©es

| Cat√©gorie | Technologie | Version | R√¥le |
|-----------|-------------|---------|------|
| **Langage** | Python | 3.12 | Core |
| **RDF** | rdflib | 7.1.1 | Manipulation graphes RDF |
| **NLP** | spaCy | 3.8.2 | NER fran√ßais (entit√©s nomm√©es) |
| **NLP** | fr_core_news_sm | 3.8.0 | Mod√®le fran√ßais spaCy |
| **LLM API** | Groq | 0.13.0 | Inf√©rence LLM ultra-rapide |
| **LLM** | Llama-3.1-8B-Instant | 8B params | Extraction relations |
| **Visualisation** | NetworkX | 3.2.1 | Graphes |
| **Visualisation** | Matplotlib | 3.8.2 | Plots |
| **HTTP** | requests | 2.32.5 | Appels API |

### 4. LLM Integration : Groq API

**Pourquoi Groq ?**
- ‚ö° Inf√©rence ultra-rapide (100-300 tokens/sec)
- üÜì **Gratuit** (pas de carte bancaire requise)
- üîÑ Disponibilit√© stable (vs Hugging Face API deprecated)
- üéØ Mod√®les optimis√©s pour la production
- üöÄ GroqCloud offre acc√®s gratuit aux derniers mod√®les

**Configuration API :**
```python
from groq import Groq
import time
import os

client = Groq(api_key=os.getenv("GROQ_API_KEY"))

response = client.chat.completions.create(
    model="llama-3.1-8b-instant",  # Meta Llama 3.1
    messages=[{"role": "user", "content": prompt}],
    temperature=0,  # D√©terministe
    max_tokens=50
)

relation = response.choices[0].message.content.strip()
```

**Prompt Engineering :**
```python
prompt = f"""
Tu es un expert en extraction de relations s√©mantiques.
Contexte : "{entity1}" et "{entity2}" apparaissent dans le m√™me texte.
Analyse leur relation et r√©ponds avec UN SEUL mot parmi :
- worksAt (travaille √†)
- studiesAt (√©tudie √†)
- teaches (enseigne)
- collaboratesWith (collabore avec)
- locatedIn (situ√© √†)
- manages (g√®re)
- relatedTo (autre relation)
NE r√©ponds qu'avec le mot-cl√©, RIEN d'autre.
"""
```

**Exemple de R√©sultat :**
```
üöÄ Appel API Groq (Llama-3) pour : Zoubida Kedad ‚Üî Universit√© de Versailles
ü§ñ Groq/Llama-3 a d√©tect√© : Zoubida Kedad --[worksAt]--> Universit√© de Versailles
```

**Syst√®me de Fallback √† 3 Niveaux :**
1. **Niveau 1** : Groq API (Llama-3.1) - extraction intelligente via LLM
2. **Niveau 2** : Analyse linguistique (spaCy + heuristiques sur tokens)
3. **Niveau 3** : Relation par d√©faut (`ex:relatedTo`)

---
---

## üí° R√©ification et M√©tadonn√©es

‚úÖ **R√©ification RDF** :
- Chaque relation importante est r√©ifi√©e avec un `ex:Statement`
- M√©tadonn√©es ajout√©es : `dc:source` (tra√ßabilit√© du texte source)
- Permet d'annoter les triplets RDF (qui a dit quoi, quand, o√π)

**Exemple de r√©ification :**
```turtle
ex:Statement_Zoubida_Kedad_worksAt_Universite_de_Versailles
    rdf:type ex:Statement ;
    rdf:subject ex:Zoubida_Kedad ;
    rdf:predicate ex:worksAt ;
    rdf:object ex:Universite_de_Versailles ;
    dc:source "Zoubida Kedad est professeure √† l'Universit√© de Versailles." ;
    ex:confidence "0.92"^^xsd:float .
```

---

## üì¶ Installation et Pr√©requis

### Pr√©requis Syst√®me
- **Python 3.12+** (test√© avec 3.12)
- **pip** (gestionnaire de paquets Python)
- Connexion Internet (pour Groq API et t√©l√©chargement mod√®le spaCy)

### Installation Compl√®te

#### 1. Cloner le projet
```bash
cd ~/T√©l√©chargements/web_semantique
```

#### 2. Installer les d√©pendances Python
```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```
rdflib==7.1.1
spacy==3.8.2
networkx==3.2.1
matplotlib==3.8.2
requests==2.32.5
huggingface-hub==0.20.0
groq==0.13.0
streamlit       # Interface web
pillow          # Traitement d'images
```

#### 3. T√©l√©charger le mod√®le fran√ßais spaCy
```bash
python -m spacy download fr_core_news_sm
```

#### 4. Configuration de l'API Groq

**Option A : Utiliser la cl√© fournie (pr√™te √† l'emploi)**
```python
# D√©j√† configur√©e dans kg_extraction_semantic_web.py ligne 45
API_KEY = ""
```

**Option B : Obtenir votre propre cl√© gratuite**
1. Cr√©er un compte gratuit : https://console.groq.com/
2. Aller dans "API Keys" et g√©n√©rer une cl√©
3. Remplacer la cl√© ligne 45 dans `kg_extraction_semantic_web.py`

---

## üöÄ Utilisation

### üåê Interface Web Streamlit (Nouveau !)

**Lancez l'interface web interactive :**

```bash
./run_streamlit.sh
```

Ou manuellement :

```bash
source venv/bin/activate
streamlit run app_streamlit.py
```

**üéØ Fonctionnalit√©s de l'interface :**
- ‚ú® Saisie de texte interactive avec exemples pr√©d√©finis
- üîÑ G√©n√©ration de graphes en temps r√©el
- üìä Visualisation graphique interactive
- üíæ Export et t√©l√©chargement RDF (Turtle + XML)
- üìà Statistiques du graphe g√©n√©r√©es
- üé® Interface moderne et responsive

**üìç L'application s'ouvre automatiquement sur : http://localhost:8501**

**üìñ Guide complet d'utilisation :** Consultez [GUIDE_STREAMLIT.md](GUIDE_STREAMLIT.md) pour un tutoriel d√©taill√© de l'interface web.

---

### üíª Ex√©cution en Ligne de Commande

**Ex√©cution Standard**
```bash
python kg_extraction_semantic_web.py
```

**Sortie attendue :**
```
üîß Initialisation du mod√®le spaCy (fr_core_news_sm)...
üìä Texte d'entr√©e : 515 caract√®res
üîç Extraction des entit√©s nomm√©es...
   ‚úì Entit√©s extraites : 4 personnes, 3 lieux, 2 organisations
üöÄ Appel API Groq (Llama-3) pour : Zoubida Kedad ‚Üî Universit√© de Versailles
ü§ñ Groq/Llama-3 a d√©tect√© : Zoubida Kedad --[worksAt]--> Universit√© de Versailles
üìà G√©n√©ration du graphe de connaissances...
‚úì Graphe export√© en TURTLE : knowledge_graph.ttl
‚úì Graphe export√© en RDF/XML : knowledge_graph.xml
‚úì Visualisation g√©n√©r√©e : graphe_connaissance.png
‚úì Nombre total de triplets : 73
```

### Fichiers G√©n√©r√©s

| Fichier | Format | Description | Taille |
|---------|--------|-------------|--------|
| `knowledge_graph.ttl` | Turtle | Format RDF lisible par humains | ~3.6 KB |
| `knowledge_graph.xml` | RDF/XML | Format W3C standard interop√©rable | ~8.2 KB |
| `graphe_connaissance.png` | PNG | Visualisation graphique | ~80 KB |

### Validation des Fichiers RDF

**Validation Turtle :**
```bash
rapper -i turtle -o ntriples knowledge_graph.ttl > /dev/null
# Si succ√®s : pas d'erreur affich√©e
```

**Validation RDF/XML :**
```bash
rapper -i rdfxml -o ntriples knowledge_graph.xml > /dev/null
```

### Requ√™tes SPARQL d'Exemple

**1. Lister toutes les personnes :**
```sparql
PREFIX foaf: <http://xmlns.com/foaf/0.1/>
SELECT ?person ?name WHERE {
  ?person rdf:type foaf:Person .
  ?person foaf:name ?name .
}
```

**2. Trouver qui travaille o√π (avec LLM) :**
```sparql
PREFIX ex: <http://example.org/ontology/>
SELECT ?person ?org WHERE {
  ?person ex:worksAt ?org .
}
```

**3. Lister les cours valid√©s (restriction OWL) :**
```sparql
PREFIX ex: <http://example.org/ontology/>
SELECT ?course ?author WHERE {
  ?course rdf:type ex:ValidatedCourse .
  ?course ex:author ?author .
}
```

---

## üß™ Tests et Validation

### 1. Tests Automatiques des 3 Corrections
```bash
python test_corrections.py
```

**R√©sultat attendu :**
```
‚úÖ Test 1 : Restriction OWL d√©tect√©e
‚úÖ Test 2 : Appel API Groq valid√©
‚úÖ Test 3 : Double s√©rialisation valid√©e (TTL + XML)
====================================
‚ú® TOUS LES TESTS SONT PASS√âS ! ‚ú®
====================================
```

### 2. D√©monstration Compl√®te
```bash
chmod +x demo.sh
./demo.sh
```

**R√©sultat attendu :**
```
üé¨ D√©monstration compl√®te du projet...
üì¶ Installation des d√©pendances...
üß™ Tests des 3 corrections acad√©miques...
üöÄ Ex√©cution du script principal...
‚úÖ Script principal ex√©cut√©
‚úÖ 2 fichiers RDF g√©n√©r√©s (TTL + XML)
‚úÖ 3 corrections acad√©miques valid√©es
‚ú® D√âMONSTRATION TERMIN√âE AVEC SUCC√àS !
```

### 3. Validation Manuelle des Restrictions OWL
```bash
python -c "
from rdflib import Graph
g = Graph()
g.parse('knowledge_graph.ttl', format='turtle')
restrictions = list(g.query('''
    PREFIX owl: <http://www.w3.org/2002/07/owl#>
    SELECT ?class ?property ?valueFrom WHERE {
        ?class rdfs:subClassOf ?restriction .
        ?restriction rdf:type owl:Restriction .
        ?restriction owl:onProperty ?property .
        ?restriction owl:someValuesFrom ?valueFrom .
    }
'''))
print(f'‚úÖ Restrictions OWL trouv√©es : {len(restrictions)}')
for r in restrictions:
    print(f'   ‚Ä¢ {r}')
"
```

---

## üìä R√©sultats et Performances

### Statistiques d'Ex√©cution

| M√©trique | Valeur |
|----------|--------|
| **Texte d'entr√©e** | 515 caract√®res |
| **Entit√©s d√©tect√©es** | 9 (4 PER, 3 LOC, 2 ORG) |
| **Appels API Groq** | ~10-15 (selon paires d'entit√©s) |
| **Temps API moyen** | 200-400ms par appel |
| **Triplets RDF g√©n√©r√©s** | 73 |
| **Classes OWL** | 5 (dont 1 avec restriction) |
| **ObjectProperties** | 8 |
| **DatatypeProperties** | 4 |
| **Statements r√©ifi√©s** | ~10 |

### Exemple de D√©tection LLM

**Entr√©e :** "Zoubida Kedad est professeure √† l'Universit√© de Versailles."

**Pipeline :**
1. **spaCy NER** ‚Üí D√©tecte `Zoubida Kedad` (PER) et `Universit√© de Versailles` (ORG)
2. **Groq API** ‚Üí Prompt envoy√© √† Llama-3.1-8B
3. **LLM r√©pond** ‚Üí `worksAt`
4. **RDF g√©n√©r√©** :
```turtle
ex:Zoubida_Kedad rdf:type foaf:Person ;
    foaf:name "Zoubida Kedad" ;
    ex:worksAt ex:Universite_de_Versailles .

ex:Universite_de_Versailles rdf:type schema:Organization ;
    schema:name "Universit√© de Versailles" .
```

---

## üêõ Troubleshooting

### Probl√®me 1 : Erreur API Groq
**Sympt√¥me :**
```
‚ùå Erreur API Groq : 400 - The model `llama3-8b-8192` does not exist
```

**Solution :**
Le mod√®le a √©t√© mis √† jour. Utiliser `llama-3.1-8b-instant` :
```python
# Ligne 264 de kg_extraction_semantic_web.py
model="llama-3.1-8b-instant",  # ‚úÖ Mod√®le actif
```

### Probl√®me 2 : Hugging Face API deprecated
**Sympt√¥me :**
```
410 Client Error: Gone for url: https://api-inference.huggingface.co/models/...
```

**Explication :**
L'infrastructure Hugging Face `api-inference.huggingface.co` a √©t√© d√©pr√©ci√©e en janvier 2026.

**Solution :**
Le projet utilise maintenant **Groq API** qui est stable et gratuit.

### Probl√®me 3 : Mod√®le spaCy manquant
**Sympt√¥me :**
```
OSError: [E050] Can't find model 'fr_core_news_sm'
```

**Solution :**
```bash
python -m spacy download fr_core_news_sm
```

### Probl√®me 4 : Cl√© API invalide
**Sympt√¥me :**
```
AuthenticationError: Invalid API key
```

**Solution :**
1. V√©rifier la cl√© ligne 45 : `API_KEY = "gsk_xxPVc9O0..."`
2. Ou obtenir une nouvelle cl√© gratuite : https://console.groq.com/

### Probl√®me 5 : Fallback activ√© trop souvent
**Sympt√¥me :**
```
‚ö† Fallback linguistique utilis√©
```

**Explication :**
L'API a renvoy√© une erreur ou un timeout ‚Üí le syst√®me bascule sur l'analyse linguistique (comportement normal).

**Pour forcer l'API uniquement :**
```python
# Ligne 330 : Commenter le fallback
# relation = predict_relation_linguistic(entity1, entity2, context)
```

---

## üìö Structure du Projet

```
web_semantique/
‚îú‚îÄ‚îÄ kg_extraction_semantic_web.py  # Script principal (906 lignes)
‚îú‚îÄ‚îÄ app_streamlit.py               # üåê Interface web Streamlit (NOUVEAU)
‚îú‚îÄ‚îÄ run_streamlit.sh               # Script de lancement interface web
‚îú‚îÄ‚îÄ requirements.txt                # D√©pendances Python
‚îú‚îÄ‚îÄ test_corrections.py             # Tests automatiques (3 corrections)
‚îú‚îÄ‚îÄ demo.sh                         # Script de d√©monstration
‚îú‚îÄ‚îÄ README.md                       # Documentation (ce fichier)
‚îú‚îÄ‚îÄ knowledge_graph.ttl             # Sortie Turtle (g√©n√©r√©)
‚îú‚îÄ‚îÄ knowledge_graph.xml             # Sortie RDF/XML (g√©n√©r√©)
‚îú‚îÄ‚îÄ graphe_connaissance.png         # Visualisation (g√©n√©r√©)
‚îî‚îÄ‚îÄ venv/                           # Environnement virtuel
```

---

## üéì Contexte Acad√©mique

### Sujet du Projet
**Sujet 1 : Architecture T-Box/A-Box avec R√©ification**
- Impl√©mentation d'une ontologie compl√®te (sch√©ma + instances)
- Distinction claire entre T-Box (terminologie) et A-Box (assertions)
- R√©ification RDF pour annotation de triplets
- Respect strict des standards OWL 2 et RDFS du W3C

### Objectifs P√©dagogiques Atteints
‚úÖ Ma√Ætrise des ontologies OWL (Classes, Propri√©t√©s, Restrictions)
‚úÖ Diff√©renciation OWL vs RDFS (Restrictions avec BNode)
‚úÖ Int√©gration de technologies NLP modernes (spaCy, LLM)
‚úÖ S√©rialisation RDF multi-format (Turtle, RDF/XML)
‚úÖ R√©ification RDF pour m√©tadonn√©es
‚úÖ Requ√™tes SPARQL sur graphes de connaissances
‚úÖ Interop√©rabilit√© avec ontologies standards (FOAF, Schema.org)

### Innovations Techniques
üî• **Int√©gration LLM r√©elle** : Groq API + Llama-3.1-8B-Instant
üî• **Prompt Engineering** : Template optimis√© pour extraction de relations
üî• **Fallback intelligent** : 3 niveaux de r√©silience (API ‚Üí linguistique ‚Üí d√©faut)
üî• **Performance** : Inf√©rence ultra-rapide (200-400ms par relation)

---

## üìñ R√©f√©rences et Standards

### Standards W3C Respect√©s
- [OWL 2 Web Ontology Language](https://www.w3.org/TR/owl2-overview/)
- [RDF 1.1 Concepts](https://www.w3.org/TR/rdf11-concepts/)
- [RDF Schema 1.1](https://www.w3.org/TR/rdf-schema/)
- [Turtle - Terse RDF Triple Language](https://www.w3.org/TR/turtle/)
- [RDF 1.1 XML Syntax](https://www.w3.org/TR/rdf-syntax-grammar/)
- [SPARQL 1.1 Query Language](https://www.w3.org/TR/sparql11-query/)

### Ontologies Utilis√©es
- [FOAF (Friend of a Friend)](http://xmlns.com/foaf/spec/) - Repr√©sentation de personnes
- [Schema.org](https://schema.org/) - Vocabulaire standard du Web
- [Dublin Core Metadata](https://www.dublincore.org/specifications/dublin-core/dcmi-terms/) - M√©tadonn√©es

### Technologies et APIs
- [spaCy](https://spacy.io/) - Industrial-Strength NLP
- [RDFLib](https://rdflib.readthedocs.io/) - Python RDF Library
- [Groq API](https://console.groq.com/docs/quickstart) - Ultra-fast LLM Inference
- [Meta Llama 3.1](https://ai.meta.com/blog/meta-llama-3-1/) - LLM 8B parameters

---

## üèÜ Fonctionnalit√©s Avanc√©es

### 1. Normalisation Intelligente des URIs
```python
def normaliser_uri(texte: str) -> str:
    """Supprime accents, espaces, caract√®res sp√©ciaux"""
    texte = unicodedata.normalize('NFD', texte)
    texte = ''.join(c for c in texte if unicodedata.category(c) != 'Mn')
    texte = texte.replace(' ', '_').replace("'", '_')
    return ''.join(c for c in texte if c.isalnum() or c == '_')
```

### 2. D√©tection Contextuelle de Relations
**Analyse linguistique de fallback :**
- Mots-cl√©s : "professeur", "enseigne", "travaille" ‚Üí `ex:worksAt`
- Mots-cl√©s : "√©tudiant", "master", "√©tudie" ‚Üí `ex:studiesAt`
- Mots-cl√©s : "collabore", "√©quipe", "projet" ‚Üí `ex:collaboratesWith`

### 3. M√©tadonn√©es de Confiance
```python
# Score de confiance pour les relations d√©tect√©es
statement.add(EX.confidence, Literal(0.92, datatype=XSD.float))
```

### 4. Export Multi-format Simultan√©
```python
# Turtle (lisible)
graph.serialize(destination="knowledge_graph.ttl", format="turtle")
# RDF/XML (standard)
graph.serialize(destination="knowledge_graph.xml", format="xml")
```

---

## üé¨ Cas d'Usage R√©els

### Exemple 1 : Publication Acad√©mique
**Texte :**
```
Jean Dupont et Marie Martin ont publi√© un article sur l'IA √† Paris.
```

**Extraction :**
- `Jean Dupont` (PER) ‚Üí `foaf:Person`
- `Marie Martin` (PER) ‚Üí `foaf:Person`
- `Paris` (LOC) ‚Üí `schema:Place`
- Relation LLM : `Jean Dupont` **collaboratesWith** `Marie Martin`
- M√©tadonn√©e : `dc:source = "Jean Dupont et Marie Martin ont publi√©..."`

### Exemple 2 : Affiliation Universitaire
**Texte :**
```
Zoubida Kedad est professeure √† l'Universit√© de Versailles.
```

**Extraction :**
- `Zoubida Kedad` (PER) ‚Üí `foaf:Person`
- `Universit√© de Versailles` (ORG) ‚Üí `schema:Organization`
- Relation LLM : `Zoubida Kedad` **worksAt** `Universit√© de Versailles`
- Sortie API : `ü§ñ Groq/Llama-3 a d√©tect√© : worksAt`

---

## üî¨ Analyses Possibles avec SPARQL

### 1. R√©seau de Collaboration
```sparql
PREFIX ex: <http://example.org/ontology/>
PREFIX foaf: <http://xmlns.com/foaf/0.1/>

SELECT ?person1 ?person2 WHERE {
  ?person1 ex:collaboratesWith ?person2 .
  ?person1 foaf:name ?name1 .
  ?person2 foaf:name ?name2 .
}
```

### 2. Affiliations Acad√©miques
```sparql
PREFIX ex: <http://example.org/ontology/>
SELECT ?person ?org WHERE {
  ?person ex:worksAt ?org .
}
```

### 3. Documents avec M√©tadonn√©es
```sparql
PREFIX ex: <http://example.org/ontology/>
PREFIX dc: <http://purl.org/dc/elements/1.1/>

SELECT ?doc ?author ?source WHERE {
  ?doc rdf:type ex:ValidatedCourse .
  ?doc ex:author ?author .
  ?stmt rdf:predicate ex:author .
  ?stmt dc:source ?source .
}
```

---

## üìà Am√©liorations Futures

### Court Terme
- [ ] Support de mod√®les LLM multilingues (anglais, espagnol)
- [ ] D√©tection de relations temporelles (avant/apr√®s)
- [ ] Export au format JSON-LD
- [ ] Interface web Flask pour visualisation interactive

### Moyen Terme
- [ ] Fine-tuning du LLM sur corpus acad√©mique fran√ßais
- [ ] Extraction d'entit√©s complexes (dates, montants, emails)
- [ ] Int√©gration avec DBpedia et Wikidata (linking)
- [ ] API REST pour extraction en temps r√©el

### Long Terme
- [ ] Apprentissage par renforcement sur feedback utilisateur
- [ ] Graphe de connaissances distribu√© (RDF*-star)
- [ ] Raisonnement automatique avec Pellet/HermiT
- [ ] Publication sur LOD Cloud

---

## ü§ù Contributeurs

**√âtudiant :** Master 2 Web S√©mantique  
**Superviseur Acad√©mique :** [Nom du professeur]  
**Institution :** [Nom de l'universit√©]  
**Ann√©e :** 2025-2026

---

## üìÑ Licence

Ce projet est d√©velopp√© dans un cadre acad√©mique et n'est pas destin√© √† une utilisation commerciale.

**Restrictions :**
- Code source : Usage acad√©mique uniquement
- Ontologies : Conformes aux licences FOAF, Schema.org, Dublin Core
- API Groq : Soumise aux [conditions d'utilisation Groq](https://console.groq.com/docs/terms)
- Mod√®le Llama-3.1 : [Licence Meta Llama 3.1](https://ai.meta.com/llama/license/)

---

## üìû Support et Contact

**Questions Techniques :**
- Consulter les fichiers de documentation dans `Docs/`
- Lire la section **Troubleshooting** ci-dessus
- Ex√©cuter `python test_corrections.py` pour diagnostiquer

**Rapports de Bugs :**
1. V√©rifier que toutes les d√©pendances sont install√©es
2. Confirmer que la cl√© API Groq est valide
3. Tester avec `./demo.sh` pour reproduire le probl√®me

**Ressources Utiles :**
- [Documentation RDFLib](https://rdflib.readthedocs.io/)
- [Documentation spaCy](https://spacy.io/usage)
- [Groq API Docs](https://console.groq.com/docs/quickstart)
- [W3C OWL 2 Primer](https://www.w3.org/TR/owl2-primer/)

---

## ‚ú® Remerciements

Merci aux √©quipes et projets open-source suivants :
- **W3C** pour les standards du Web S√©mantique
- **Meta AI** pour Llama 3.1
- **Groq** pour l'infrastructure d'inf√©rence ultra-rapide
- **Explosion AI** pour spaCy
- **RDFLib Community** pour la biblioth√®que RDF Python
- **FOAF & Schema.org** pour les ontologies standard

---

---

*Derni√®re mise √† jour : 16 janvier 2026*  
*Version : 2.0 (Groq API + Llama-3.1-8B-Instant)*  
*Projet Master 2 Web S√©mantique - Architecture T-Box/A-Box avec LLM*

# Configuration API Hugging Face
API_URL = "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2"
HF_TOKEN = "votre_token_ici"
HEADERS = {"Authorization": f"Bearer {HF_TOKEN}"}

def predict_relation_real_api(entity1: str, entity2: str, sentence: str):
    """
    Appel API R√âEL vers Mistral-7B pour pr√©diction de relations.
    Plus de simulation - vrai LLM en production !
    """
    prompt = f"""[INST] Tu es un expert en Web S√©mantique.
Analyse la phrase suivante : "{sentence}"
Quelle est la relation entre "{entity1}" et "{entity2}" ?

Choisis UNIQUEMENT une relation parmi cette liste :
- teaches (pour enseigner)
- worksAt (pour travailler quelque part)
- writtenBy (pour un auteur)
- locatedIn (pour un lieu)
- relatedTo (si autre)

R√©ponds uniquement avec le mot de la relation, rien d'autre. [/INST]
"""
    
    payload = {
        "inputs": prompt,
        "parameters": {"max_new_tokens": 10, "return_full_text": False}
    }
    
    response = requests.post(API_URL, headers=HEADERS, json=payload)
    result = response.json()
    relation = result[0]['generated_text'].strip()
    
    print(f"ü§ñ Mistral-7B : {entity1} --[{relation}]--> {entity2}")
    return relation
```

### Visualisation du Graphe

```python
def visualize_knowledge_graph(graph, output_file="graphe_connaissance.png"):
    """
    G√©n√®re une visualisation du graphe avec NetworkX et Matplotlib.
    """
    G = nx.DiGraph()
    
    # Extraction des n≈ìuds et ar√™tes depuis le graphe RDF
    # Colorisation par type d'entit√©
    # Export en PNG haute r√©solution
    
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
```

### Double S√©rialisation (Turtle + RDF/XML) ‚≠ê

```python
# FORMAT 1 : TURTLE (lisible par l'humain)
turtle_output = graph.serialize(format='turtle')
with open("knowledge_graph.ttl", 'w', encoding='utf-8') as f:
    f.write(turtle_output)

# FORMAT 2 : RDF/XML (standard historique du W3C, utilis√© dans les cours)
xml_output = graph.serialize(format='xml')
with open("knowledge_graph.xml", 'w', encoding='utf-8') as f:
    f.write(xml_output)

print(f"‚úì Double s√©rialisation : Turtle + RDF/XML")
```

### R√©ification d'un Triplet

```python
def reify_statement(graph, subject, predicate, obj, source_file):
    statement_uri = DATA[f"statement_{hash((subject, predicate, obj))}"]
    
    # D√©claration du n≈ìud Statement
    graph.add((statement_uri, RDF.type, RDF.Statement))
    
    # D√©composition du triplet
    graph.add((statement_uri, RDF.subject, subject))
    graph.add((statement_uri, RDF.predicate, predicate))
    graph.add((statement_uri, RDF.object, obj))
    
    # M√©tadonn√©e : source d'extraction
    graph.add((statement_uri, DC.source, Literal(source_file)))
```

---

## üìñ Concepts Th√©oriques Appliqu√©s

### T-Box vs A-Box

- **T-Box (Terminological Box)** : Sch√©ma conceptuel, d√©finitions des classes et propri√©t√©s
- **A-Box (Assertional Box)** : Donn√©es factuelles, instances concr√®tes

### OWL Property Hierarchy

```
owl:ObjectProperty    ‚Üí Relie des ressources (URI ‚Üí URI)
owl:DatatypeProperty  ‚Üí Relie ressources et litt√©raux (URI ‚Üí Literal)
```

### R√©ification RDF

Permet de faire des assertions sur des assertions :
```turtle
:statement1 rdf:type rdf:Statement ;
    rdf:subject :ZoubidaKedad ;
    rdf:predicate :enseigne_a ;
    rdf:object :UniversiteVersailles ;
    dc:source "texte_exemple.txt" .
```

---

## üéì Conformit√© Acad√©mique

Ce projet respecte les exigences suivantes :

‚úÖ S√©paration stricte T-Box / A-Box  
‚úÖ Distinction ObjectProperty vs DatatypeProperty  
‚úÖ Contraintes rdfs:domain et rdfs:range  
‚úÖ **Restrictions OWL explicites** (ValidatedCourse) ‚≠ê  
‚úÖ R√©ification RDF compl√®te  
‚úÖ Standards OWL et RDFS  
‚úÖ **Ontologies standards** : FOAF et Schema.org  
‚úÖ **Extraction de relations via API Hugging Face R√âELLE (Mistral-7B)** üî• ‚≠ê  
‚úÖ **Double s√©rialisation** : Turtle + RDF/XML ‚≠ê  
‚úÖ **Visualisation graphique** interactive  
‚úÖ Code comment√© et document√©  
‚úÖ Script de tests de validation inclus  

---

## üìù Documentation des Corrections Acad√©miques

### Fichiers de r√©f√©rence

1. **CORRECTIONS_ACADEMIQUES.md** - Rapport d√©taill√© pour le superviseur
   - Explication technique des 3 corrections
   - Exemples de code avec num√©ros de lignes
   - R√©sultats des tests de validation

2. **GUIDE_PRESENTATION.md** - Guide rapide pour la pr√©sentation orale
   - Script de pr√©sentation (1 minute)
   - Points cl√©s √† montrer
   - Checklist avant pr√©sentation

3. **test_corrections.py** - Suite de tests automatiques
   - Validation de la restriction OWL
   - Validation du prompt engineering
   - Validation de la double s√©rialisation

### Commandes de validation

```bash
# Ex√©cuter tous les tests
python test_corrections.py

# V√©rifier les fichiers g√©n√©r√©s
ls -lh knowledge_graph.*

# Afficher la restriction OWL dans le XML
grep -A 5 "owl:Restriction" knowledge_graph.xml
```

---

## üìö R√©f√©rences

### Standards du Web S√©mantique
- **OWL 2 Web Ontology Language** : [W3C Recommendation](https://www.w3.org/TR/owl2-overview/)
- **RDF 1.1 Concepts** : [W3C Recommendation](https://www.w3.org/TR/rdf11-concepts/)
- **RDFS 1.1** : [W3C Recommendation](https://www.w3.org/TR/rdf-schema/)
- **FOAF Vocabulary** : [Friend of a Friend](http://xmlns.com/foaf/spec/)
- **Schema.org** : [Ontologie standard](https://schema.org/)

### Biblioth√®ques Python
- **spaCy** : [Documentation officielle](https://spacy.io/)
- **rdflib** : [Documentation officielle](https://rdflib.readthedocs.io/)
- **NetworkX** : [Documentation officielle](https://networkx.org/)
- **Matplotlib** : [Documentation officielle](https://matplotlib.org/)

---

## üìù Auteur

**Projet Master 2 - Web S√©mantique**  
Sujet 1 : Extraction de graphes de connaissances √† partir de texte

*Date de r√©alisation : 15 janvier 2026*
# web_semantique
# web_semantique
